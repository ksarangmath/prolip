{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../pretrained_classifiers\")\n",
    "sys.path.insert(0, \"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "import numpy as np\n",
    "import io\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "import torch.onnx\n",
    "from multiprocessing import Pool\n",
    "from joblib import Parallel, delayed\n",
    "import _thread as thread\n",
    "from numba import njit, prange\n",
    "import time\n",
    "import itertools\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from utee import selector\n",
    "from boxprop import *\n",
    "from boxprop_optimized import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_gpu = 1 if torch.cuda.is_available() else 0\n",
    "\n",
    "# load the models\n",
    "from dcgan import Discriminator, Generator\n",
    "\n",
    "D = Discriminator(ngpu=1).eval()\n",
    "G = Generator(ngpu=1).eval()\n",
    "\n",
    "# load weights\n",
    "D.load_state_dict(torch.load('weights/netD_epoch_99.pth', map_location=torch.device('cpu')))\n",
    "G.load_state_dict(torch.load('weights/netG_epoch_99.pth', map_location=torch.device('cpu')))\n",
    "if torch.cuda.is_available():\n",
    "    D = D.cuda()\n",
    "    G = G.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generate some images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 1\n",
    "latent_size = 100\n",
    "\n",
    "fixed_noise = torch.randn(batch_size, latent_size, 1, 1)\n",
    "if torch.cuda.is_available():\n",
    "    fixed_noise = fixed_noise.cuda()\n",
    "fake_images = G(fixed_noise)\n",
    "\n",
    "\n",
    "\n",
    "# z = torch.randn(batch_size, latent_size).cuda()\n",
    "# z = Variable(z)\n",
    "# fake_images = G(z)\n",
    "\n",
    "fake_images_np = fake_images.cpu().detach().numpy()\n",
    "fi = fake_images_np\n",
    "fake_images_np = fake_images_np.reshape(fake_images_np.shape[0], 28, 28)\n",
    "R, C = 6, 6\n",
    "for i in range(batch_size):\n",
    "    plt.subplot(R, C, i + 1)\n",
    "    plt.imshow(fake_images_np[i], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0420], grad_fn=<SqueezeBackward1>)\n"
     ]
    }
   ],
   "source": [
    "outputs = D(fake_images)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.1921790010528639\n",
      "1\n",
      "0.349950019037351\n",
      "2\n",
      "0.7444940080167726\n",
      "3\n",
      "1.3275262510869652\n",
      "3\n",
      "0.0011462719412520528\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "#boxprop_optimized for mnist GAN\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEQAAABBCAYAAABo3gIBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAFy0lEQVR4nO2aT2xUVRTGf6dDOzT0z1jaTAkUqWJCygKsRknqDkiMG8VAkYUscUOiEReWFSzciSFhYVLDv4WkCbEhLkwMCwgIwYKkCEpt2sYgOkgNUAZmmCnvfS5mWsqj7UxnptMpeV9y0/fuu/eeM1/POfec965JwscTlM21AqUGnxAPfEI88AnxwCfEA58QD/IixMzeNrM/zGzAzD4vlFJzCcs1DzGzANAPbARuAheBbZJ+L5x6xUc+FvIGMCBpSFIS6ALeLYxac4cFecxdCvw14f4m8KZ3kJntAHakb1/LQ17ekGSZxuRDyGSLP+N/kjqBTgAzK/k6IR+XuQk0TbhfBvyTnzolAEk5NVLWNQQ0AxXAFWB1hjmay5bN78rZZSQ9NrOdwI9AADgk6bdc1ysV5Lzt5iQszxiyYMEC6urquH37dk7zZzuozirKy8sBaG9vZ8OGDaxbtw5JBINBenp66OzsBODUqVMFlVuShCxfvpyzZ88C0NTUhOM4JJNJgsEgZWVlNDc3U1dXB0AikeD8+fOFE55rUM0xEGcMfG1tbert7VUmuK4r13XV09OjlpaWggXVkiKktrZWsVhMsVhM0WhU0WhUiURCjx8/1rlz53TmzBm5rvsUMclkUidOnFBNTc3zRUgwGFRHR4dGR0efsoBoNKrDhw9r9erVWrVqlY4dO/aMpSSTSR09elSLFy/OmxC//PeiFCwkGAzq5MmTcl1XsVhM8Xhc3d3d6u7u1qZNm1RdXT0+NhQKKR6Py3EcOY6jeDyukZEROY6jSCSihoaGvCykJPKQxsZGhoaGqKysRBLDw8OsWbMGgFu3bj0zfu3atePP+/r6GBkZ4cKFCyxatIjTp0+zcePGSeUrizykJCyko6NDjuMomUxqcHBQS5cunXFaHggENDg4qEQioc2bN8/voHrjxo3xADnVj8mmHTlyRK7ramhoaH4H1cbGRgBc16WhoSHndWpqajAz6uvrc1emFCwkGo1qDP39/dMGxqnarl279OjRI0nSlStX5rfL7Nu376mEa2BgQOFwWOFwOCMRFRUV2r59+zipjuNo796989tlSgklse3W1tbS19c3HksAHMcB4Pjx43R1dZFIJLh79y7hcJjR0VG2bt0KwJYtW6isrMQstaM+ePCAUCg0Pn8iNF+2XUDt7e16+PChpsOYWzmOM+nz+/fva/369XklZiVDCKCVK1dq//79unfv3ngtMxUxY5nqnTt3NDw8rIMHD2rZsmXTrp+NjiXhMp4xVFVVEQ6HAQiFQixcuJBAIEAkEiGRSNDa2kpraysABw4cyPoNmrJwmZIjJMt1yEXvbAjJuMuYWZOZnTKz62b2m5l9nO7fY2Z/m1lvur0zYw1zxGz+EzNaiJktAZZIumxm1cAvwHtAO/BA0pdZC5vjD1XZWEjGd6qSIkAkfR01s+ukPmM+l5hRYmZmK4BXgZ/TXTvN7FczO2RmL0wxZ4eZXTKzS3lpWizMYMusIuUu76fvw6Q+UJUBX5D6UJXXtjvbrWB5CFBO6gvdp1M8XwFcex4IyRhDLJUTHwSuS/pqQv+SdHwB2ARcy7QW8B/wMP23GKifIOvFbCZks8u8BZwFrgJuuns3sA1YS4r9P4GPJhA03XqXJL2ejXL5IhdZ2ewyPzH5WZAfZiJovsAv/z2YC0I6S1lWUWuZ+QDfZTzwCfGgaITM9qnnglXlhXobliFDDQCDwEs8OaDXUmAZS4DW9HU1qVPWLcAe4LNs1ymWhcz6qWdJEUmX09dRIKeqvFiETHbqedZeIeRSlY+hWIRkdeq5IILMqoDvgE8k3Qe+Bl4mVWZEgH3TzS8WIUU59Wxm5aTI+FZSN4CkfyU5klzgG1LuOyWKRchF4BUzazazCuAD4PtCCpiuKp8wLGNVXpRjmSrOqec24EPgqpn1pvt2A9vM7KmqfLpF/NTdAz9T9cAnxAOfEA98QjzwCfHAJ8QDnxAP/ge7UTkphebSUAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0420], grad_fn=<SqueezeBackward1>)\n"
     ]
    }
   ],
   "source": [
    "fake_images_np = a_o.upper\n",
    "fake_images_np = fake_images_np.reshape(fake_images_np.shape[0], 28, 28)\n",
    "R, C = 6, 6\n",
    "for i in range(batch_size):\n",
    "    plt.subplot(R, C, i + 1)\n",
    "    plt.imshow(fake_images_np[i], cmap='gray')\n",
    "plt.show()\n",
    "print(D(torch.Tensor(a_o.upper)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building and initializing mnist parameters\n",
      "Sequential(\n",
      "  (fc1): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (relu1): ReLU()\n",
      "  (drop1): Dropout(p=0.2, inplace=False)\n",
      "  (fc2): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (relu2): ReLU()\n",
      "  (drop2): Dropout(p=0.2, inplace=False)\n",
      "  (out): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_raw, ds_fetcher, is_imagenet = selector.select('mnist')\n",
    "# ds_val = ds_fetcher(batch_size=10, train=False, val=True)\n",
    "# for idx, (data, target) in enumerate(ds_val):\n",
    "#     data =  Variable(torch.FloatTensor(data))\n",
    "#     output = model_raw(data)\n",
    "#     print(D(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (model): Sequential(\n",
       "    (fc1): Linear(in_features=784, out_features=256, bias=True)\n",
       "    (relu1): ReLU()\n",
       "    (drop1): Dropout(p=0.2, inplace=False)\n",
       "    (fc2): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (relu2): ReLU()\n",
       "    (drop2): Dropout(p=0.2, inplace=False)\n",
       "    (out): Linear(in_features=256, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_raw.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "center = torch.randn(1,100,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True 1\n",
      "True 2\n",
      "True 3\n",
      "True 4\n",
      "True 5\n",
      "True 6\n",
      "True 7\n",
      "True 8\n",
      "True 9\n",
      "True 10\n",
      "True 11\n",
      "True 12\n",
      "True 13\n",
      "tensor([[[[ 22.1732,  87.9016,  65.2818,  ...,  69.9947,  48.1911,  22.6203],\n",
      "          [ 69.8355, 273.7919, 212.5612,  ..., 225.5994, 160.8569,  72.1978],\n",
      "          [ 71.2584, 276.8326, 214.6486,  ..., 221.8024, 165.5772,  70.0158],\n",
      "          ...,\n",
      "          [ 73.4504, 254.9062, 223.1740,  ..., 291.0572, 236.8167,  96.5797],\n",
      "          [ 65.2499, 234.9788, 200.7440,  ..., 255.7771, 209.9358,  83.3470],\n",
      "          [ 24.0215,  78.4734,  74.1868,  ...,  91.0343,  80.1353,  30.9065]],\n",
      "\n",
      "         [[ 31.0545, 115.5600,  85.6173,  ...,  99.6764,  58.9167,  35.5789],\n",
      "          [143.8479, 240.7022, 388.4092,  ..., 208.9616, 246.3153,  71.2211],\n",
      "          [ 94.9811, 331.2182, 267.5133,  ..., 289.9214, 186.8287,  97.9906],\n",
      "          ...,\n",
      "          [145.2797, 259.7335, 394.7720,  ..., 321.9141, 352.5579, 112.5001],\n",
      "          [ 82.1302, 252.7834, 230.0679,  ..., 293.4373, 214.7978,  99.4312],\n",
      "          [ 47.1334,  89.1479, 130.2217,  ..., 112.4462, 119.4453,  40.5531]],\n",
      "\n",
      "         [[ 38.9609, 101.1457, 111.0969,  ...,  86.8493,  76.7256,  29.8054],\n",
      "          [ 92.3906, 260.0083, 248.4603,  ..., 230.0085, 163.7013,  76.6533],\n",
      "          [117.2502, 297.3803, 343.9710,  ..., 253.7208, 242.1897,  83.8861],\n",
      "          ...,\n",
      "          [102.6928, 271.1255, 275.2036,  ..., 331.2274, 233.1126, 113.0959],\n",
      "          [ 97.0296, 226.4582, 283.3605,  ..., 250.9162, 277.7694,  81.8983],\n",
      "          [ 37.1982,  90.9738,  95.9249,  ..., 113.0703,  78.6898,  39.4367]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 57.3145, 114.6570, 146.4931,  ...,  99.6378,  89.0302,  35.2398],\n",
      "          [107.8485, 319.5059, 299.7577,  ..., 302.6191, 200.7601, 108.0831],\n",
      "          [167.8785, 335.8321, 440.3780,  ..., 299.5425, 269.1265, 100.9759],\n",
      "          ...,\n",
      "          [114.0739, 351.6435, 315.0917,  ..., 450.5459, 287.9245, 162.2364],\n",
      "          [134.4274, 259.8411, 347.4074,  ..., 315.9036, 281.6603, 109.3326],\n",
      "          [ 38.6582, 121.7746, 106.6129,  ..., 155.5686,  98.2124,  56.4825]],\n",
      "\n",
      "         [[ 10.4473,  25.1846,  27.2709,  ...,  20.4784,  18.8124,   7.1814],\n",
      "          [ 25.7614,  54.1471,  78.6252,  ...,  50.3045,  59.6654,  17.5721],\n",
      "          [ 29.8623,  78.9933,  83.7933,  ...,  64.5798,  59.7462,  20.6751],\n",
      "          ...,\n",
      "          [ 25.3509,  55.3742,  79.4835,  ...,  68.2938,  86.3398,  24.0134],\n",
      "          [ 24.7786,  68.5553,  70.0386,  ...,  73.4779,  68.0188,  23.6829],\n",
      "          [  8.3552,  18.7705,  26.1962,  ...,  22.3668,  29.6410,   8.1492]],\n",
      "\n",
      "         [[ 42.2352, 112.7736, 110.7791,  ...,  85.0557,  71.0431,  25.8249],\n",
      "          [ 96.1421, 278.7940, 289.8358,  ..., 222.3007, 221.9069,  71.7898],\n",
      "          [125.5633, 350.8531, 340.3669,  ..., 262.9718, 224.9008,  79.4116],\n",
      "          ...,\n",
      "          [101.0948, 267.3052, 302.2875,  ..., 320.7001, 308.9666, 109.9603],\n",
      "          [100.4056, 295.1768, 273.8073,  ..., 303.0226, 250.7793,  92.2772],\n",
      "          [ 33.7539,  85.2760, 102.0281,  ..., 109.4884, 102.3940,  40.2568]]]])\n",
      "True 14\n",
      "True 15\n",
      "False\n",
      "False\n",
      "True\n",
      "False\n",
      "False\n",
      "True\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# center = torch.randn(1,100,1,1)\n",
    "size=0.05\n",
    "upper_bound = center+size\n",
    "lower_bound = center-size\n",
    "a_o = Box_o(upper_bound,lower_bound, False)\n",
    "\n",
    "size=0.001\n",
    "upper_bound = center+size\n",
    "lower_bound = center-size\n",
    "a_oo = Box_o(upper_bound,lower_bound, False)\n",
    "\n",
    "print(False in (a_oo.upper==a_o.upper),1)\n",
    "\n",
    "a_o.convTranspose2d(weight=G.state_dict()['main.0.weight'], c_out=512, kernel_size=4, stride=1, padding=0, output_padding=0)\n",
    "a_oo.convTranspose2d(weight=G.state_dict()['main.0.weight'], c_out=512, kernel_size=4, stride=1, padding=0, output_padding=0)\n",
    "print(False in (a_oo.upper==a_o.upper),2)\n",
    "\n",
    "a_o.batchNorm2d(mean=G.state_dict()['main.1.running_mean'], var=G.state_dict()['main.1.running_var'], eps=1e-05, weight=G.state_dict()['main.1.weight'], bias=G.state_dict()['main.1.bias'])\n",
    "a_oo.batchNorm2d(mean=G.state_dict()['main.1.running_mean'], var=G.state_dict()['main.1.running_var'], eps=1e-05, weight=G.state_dict()['main.1.weight'], bias=G.state_dict()['main.1.bias'])\n",
    "print(False in (a_oo.upper==a_o.upper),3)\n",
    "\n",
    "a_o.relu()\n",
    "a_oo.relu()\n",
    "print(False in (a_oo.upper==a_o.upper),4)\n",
    "\n",
    "a_o.convTranspose2d(weight=G.state_dict()['main.3.weight'], c_out=256, kernel_size=4, stride=2, padding=1, output_padding=0)\n",
    "a_oo.convTranspose2d(weight=G.state_dict()['main.3.weight'], c_out=256, kernel_size=4, stride=2, padding=1, output_padding=0)\n",
    "print(False in (a_oo.upper==a_o.upper),5)\n",
    "\n",
    "a_o.batchNorm2d(mean=G.state_dict()['main.4.running_mean'], var=G.state_dict()['main.4.running_var'], eps=1e-05, weight=G.state_dict()['main.4.weight'], bias=G.state_dict()['main.4.bias'])\n",
    "a_oo.batchNorm2d(mean=G.state_dict()['main.4.running_mean'], var=G.state_dict()['main.4.running_var'], eps=1e-05, weight=G.state_dict()['main.4.weight'], bias=G.state_dict()['main.4.bias'])\n",
    "print(False in (a_oo.upper==a_o.upper),6)\n",
    "\n",
    "a_o.relu()\n",
    "a_oo.relu()\n",
    "print(False in (a_oo.upper==a_o.upper),7)\n",
    "\n",
    "a_o.convTranspose2d(weight=G.state_dict()['main.6.weight'], c_out=128, kernel_size=4, stride=2, padding=1, output_padding=0)\n",
    "a_oo.convTranspose2d(weight=G.state_dict()['main.6.weight'], c_out=128, kernel_size=4, stride=2, padding=1, output_padding=0)\n",
    "print(False in (a_oo.upper==a_o.upper),8)\n",
    "\n",
    "a_o.batchNorm2d(mean=G.state_dict()['main.7.running_mean'], var=G.state_dict()['main.7.running_var'], eps=1e-05, weight=G.state_dict()['main.7.weight'], bias=G.state_dict()['main.7.bias'])\n",
    "a_oo.batchNorm2d(mean=G.state_dict()['main.7.running_mean'], var=G.state_dict()['main.7.running_var'], eps=1e-05, weight=G.state_dict()['main.7.weight'], bias=G.state_dict()['main.7.bias'])\n",
    "print(False in (a_oo.upper==a_o.upper),9)\n",
    "\n",
    "a_o.relu()\n",
    "a_oo.relu()\n",
    "print(False in (a_oo.upper==a_o.upper),10)\n",
    "\n",
    "a_o.convTranspose2d(weight=G.state_dict()['main.9.weight'], c_out=64, kernel_size=4, stride=2, padding=1, output_padding=0)\n",
    "a_oo.convTranspose2d(weight=G.state_dict()['main.9.weight'], c_out=64, kernel_size=4, stride=2, padding=1, output_padding=0)\n",
    "print(False in (a_oo.upper==a_o.upper),11)\n",
    "\n",
    "a_o.batchNorm2d(mean=G.state_dict()['main.10.running_mean'], var=G.state_dict()['main.10.running_var'], eps=1e-05, weight=G.state_dict()['main.10.weight'], bias=G.state_dict()['main.10.bias'])\n",
    "a_oo.batchNorm2d(mean=G.state_dict()['main.10.running_mean'], var=G.state_dict()['main.10.running_var'], eps=1e-05, weight=G.state_dict()['main.10.weight'], bias=G.state_dict()['main.10.bias'])\n",
    "print(False in (a_oo.upper==a_o.upper),12)\n",
    "\n",
    "a_o.relu()\n",
    "a_oo.relu()\n",
    "print(False in (a_oo.upper==a_o.upper),13)\n",
    "print(a_o.upper)\n",
    "\n",
    "\n",
    "a_o.convTranspose2d(weight=G.state_dict()['main.12.weight'], c_out=1, kernel_size=1, stride=1, padding=2, output_padding=0)\n",
    "a_oo.convTranspose2d(weight=G.state_dict()['main.12.weight'], c_out=1, kernel_size=1, stride=1, padding=2, output_padding=0)\n",
    "print(False in (a_oo.upper==a_o.upper),14)\n",
    "# print(a_o.lower)\n",
    "atan = a_o.tanh()\n",
    "aotan = a_oo.tanh()\n",
    "print(False in (a_oo.upper==a_o.upper),15)\n",
    "\n",
    "\n",
    "C = model_raw\n",
    "b1 = Box_o(a_oo.upper, a_oo.lower, True)\n",
    "b2 = Box_o(a_o.upper, a_o.lower, True)\n",
    "print(False in (b1.lip.upper==b2.lip.upper))\n",
    "b1.linear(C.state_dict()['model.fc1.weight'], C.state_dict()['model.fc1.bias'])\n",
    "b2.linear(C.state_dict()['model.fc1.weight'], C.state_dict()['model.fc1.bias'])\n",
    "print(False in (b1.lip.upper==b2.lip.upper))\n",
    "print(b1.relu()==b2.relu())\n",
    "print(False in (b1.lip.upper==b2.lip.upper))\n",
    "b1.linear(C.state_dict()['model.fc2.weight'], C.state_dict()['model.fc2.bias'])\n",
    "b2.linear(C.state_dict()['model.fc2.weight'], C.state_dict()['model.fc2.bias'])\n",
    "print(False in (b1.lip.upper==b2.lip.upper))\n",
    "print(b1.relu()==b2.relu())\n",
    "\n",
    "print(False in (b1.lip.upper==b2.lip.upper))\n",
    "b1.linear(C.state_dict()['model.out.weight'], C.state_dict()['model.out.bias'])\n",
    "b2.linear(C.state_dict()['model.out.weight'], C.state_dict()['model.out.bias'])\n",
    "print(False in (b1.lip.upper==b2.lip.upper))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEQAAABBCAYAAABo3gIBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAJMklEQVR4nO2aa0ycVRrHf2duHaC00kI22B1KWarY8gGmZL0ULx/YZNMb6UqsfFgjxrg1MVHWjUH9YjTExLj7wcRUu9lGkt5MbJM26Rr8IMZZG4ld6Epb0sui3bXFdgpYJnUuMO9/P8wwMgMdhkunuJl/cpJ3zpznnOf9v8/znPOcc4wkcvgJttutwGJDjpAU5AhJQY6QFOQISUGOkBTMixBjzG+NMWeNMReMMW0LpdTthJnrOsQYYwfOAb8BvgO+ApolnVk49bKP+VjIr4ELkgYkRYCDQOPCqHX74JiH7Crgv5N+fwfcm9rIGPMM8AxAQUHBhoqKCmw2G4ODgwDceeed2O12AHp7e5GEzWajsLAQgB9++GFyX4nn2Vr2ihUrGBoaMjO1mw8h03U+RUtJu4HdAHV1dTp06BCrV6+mo6MDgK1bt5Kfn8/g4CDr16/H7XYTCAQYHx8HYOXKlbhcLq5cuYJlWXNWdnh4OKN28yHkO8Az6fcvgcszCXk8MZHdu3cD8OCDDzIyMsKLL75IKBTC4XAQjUZpaWkB4OOPP+bChQvzUDOGu+66K6N284khXwFrjTFrjDEu4HHg6Dz6WxSYs4VIGjfGPAd0AnZgj6TT6WSuXr3KpUuXKCkpobu7G4DGxkZcLhcVFRU4HA7sdjuS2Lt3L8C0blJcXMymTZsAKC8vZ+fOnZSWlhIIBFi+fPmU+OJ0OsnPz8/4xbJWvF6vjhw5otHRUbndbrndbj3xxBPasWOH6urqVFBQoOLiYhljRCweJRW32622tjZFIhFNB8uy1NraOq3sPffco0x0nE8MmTXGxsbIz8/Hsiz27NkDwNDQEJs3b+axxx7j5MmTvP3227z//vtTZFesWMGVK1dwOKaqLAljDJJYu3bttGOfP38+Ix2zSojL5aKhoQGIkQNw5swZjh07Rk9PDx999BEHDx6cVnbv3r0JMn788UcGBgYAOH78OHV1dXi9XsLhMO+888608mvWrMlMyWy6THl5uXw+n3bt2pUwZZ/PN62Jp5ZPP/1UknTu3Dm1trYqLy9PeXl5Msbo5ZdfVjQald/vV3l5eZLcfffdp5GREXm93oxcJquEVFRUqLKyUmfPnlV1dbWqq6u1ZMmSjAg5f/68JKmjoyOp/umnn9bVq1cVCoV0/PjxKfEnHA5LkjZs2LD4YkhhYSHLly+ntLSUDz74AIBwOMzGjRvTyhljKCoqAuDYsWNs376dp556CoD6+nry8vIIBoN0dXVNK69ZrGpz6X8qsukycbOVJPn9fvn9fnV2ds7oLna7XX19fQnZaDSqcDiscDisUCgkn8+nBx54IMldnE6nnE6nRkdHF6/LjI2NcfHiRcrKynjjjTeA2NJ9Ak8++SSnTp3ixIkTSXL3338/69evT6r7/vvvAXj11Vc5cOAA0Wg08Z/T6cRmixl/OByenZLZtJDa2lpt27ZNlmWprKxMZWVlSV+1pqZGS5cuTbKOgoICvffeewnruHbtmpqbm2e0qpKSEpWUlOjixYsKhUKqra1dfBYSjUZpb28nEokkAunhw4cTX3FwcJBoNEpRURHbtm0DoK2tjaqqKgCCwSBbtmzhyy+/TDvOkiVLGBoaAmJL/7GxsaStg7TIpoV4vV6Nj49LkhobG9XY2Kjq6uqkWFFZWZkULyZihiRdv35dxcXFGU3TE6WpqWlWMSSrs8zkRK2vr4++vj76+/sTdQ6Hg4cffjhhEQADAwO8++67WJaF2+1mx44dacew2Wy4XC6MMRhjaG9vz3gvBMj+LBMIBCRJDodDDocj6WvabDadPn1aktTb26ve3l41NjbKGKM333xTknTkyJG0FmGMkd1uT5SdO3dq3759qq6uXnwW8nNAVoOq9NOKcWKLcDK2bNlCVVUVgUCA1tZWAD777LOkNqtWrUpktjcbY/IU3NbWluSWGSmZTZeZANOYe2dnpySpu7t7yn9er1eWZSkcDmvz5s0ZB9XPP/9clmVlnNxl3WUk3XSzeKJ+Ykc+9T9J3LhxA5/Pd9P+J3bwJ/DQQw/x6KOP0tPTk7mCi8VCtm7dmgiok+vLysp04MABSdKHH36YkWW0tLSopaVFn3zyiSzLynjazTohE2uK6V7C6XTK7/crEolo//792r9/v5599ll98cUXCSIfeeSRGcm4++67E7PMSy+9pHA4rJqamoUhhNhRQxfQD5wGno/XvwZcAk7Gy6bZWEhRUZGKioqmvExDQ4P8fr+mQ1NTU0bW0dDQkEgNSktLJWW+MMuEkFLAG38uJHaeuy5OyJ9mayGWZSkYDM74Uj6fTz6fT9FoVN98882UnbB0xeVyyWazyWazyel06vXXX884qM447UoaBAbjzwFjTD+xY8z/T8zmCwPlwH+AZcQs5Fvga2APUHQTmWeAE8AJj8ejYDCoSCQyq3wkk1JfXy9jjGpqapIyaLfbrWAwuPBBFVgK/BP4Xfz3L4gdUNmAdmIHVTO6zNGjRzUyMqKmpiY1NTWpsrJyQQjxeDxat26dli1bllQ/PDy8sDEk/vJOYid0f0xjOacyIWQCkUhEkUhEK1eu1B133KG8vLyE76e+bHNzs0KhkKLRqCzLkmVZiX66urr01ltv6fLly5Jih1VVVVXyeDzyeDy6fv36rAiZ8cKMiW0kdADDkl6YVF8ajy8YY1qBeyU9PkNffuAGcC3toAuH4kljrZZUMpNAJoTUAz6gD5hYYr4CNAM1xL7it8AfJgiaob8TkupmarcQmMtYmcwy/2D6uyB/n81APxfk0v8U3A5Cdi/mseZ8C/H/FTmXSUGOkBRkjZBbfevZGOMxxnQZY/qNMaeNMc/H618zxlwyxpyMl01pO5pNLjPXQmyJ/2+gAnAB/wLWLfAYC5KVZ8tCbvmtZ0mDknrizwFi+zezzsqzRch0t55v2RaCMaYcqAW641XPGWO+NsbsMcYUpZPNFiEZ3XpekIGMWQocAl6QNArsAn5FLM0YBP6cTj5bhMzp1vNsYYxxEiNjn6TDAJKuSIpKsoC/EnPfmyJbhNzyW8/xrPxvQL+kv0yqL53UbDtwKl0/WTm50xxuPc8BG4HfA33GmJPxuleAZmNMUlaerpPc0j0FuZVqCnKEpCBHSApyhKQgR0gKcoSkIEdICv4HihAiVaSDwT4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0874], grad_fn=<SqueezeBackward1>)\n"
     ]
    }
   ],
   "source": [
    "fake_images_np = a_oo.upper\n",
    "fake_images_np = fake_images_np.reshape(fake_images_np.shape[0], 28, 28)\n",
    "R, C = 6, 6\n",
    "for i in range(batch_size):\n",
    "    plt.subplot(R, C, i + 1)\n",
    "    plt.imshow(fake_images_np[i], cmap='gray')\n",
    "plt.show()\n",
    "print(D(torch.Tensor(a_o.upper)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115.42352"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1.getLip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "115.42352"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, cProfile\n",
    "torch.manual_seed(0)\n",
    "center = torch.randn(1,100,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         98341 function calls (98339 primitive calls) in 0.835 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        2    0.000    0.000    0.000    0.000 <__array_function__ internals>:2(prod)\n",
      "        2    0.000    0.000    0.000    0.000 <__array_function__ internals>:2(product)\n",
      "        1    0.000    0.000    0.835    0.835 <string>:1(<module>)\n",
      "        1    0.474    0.474    0.835    0.835 boxprop_optimized.py:53(relu)\n",
      "        4    0.000    0.000    0.000    0.000 fromnumeric.py:2838(_prod_dispatcher)\n",
      "        2    0.000    0.000    0.000    0.000 fromnumeric.py:2843(prod)\n",
      "        2    0.000    0.000    0.000    0.000 fromnumeric.py:3602(product)\n",
      "        2    0.000    0.000    0.000    0.000 fromnumeric.py:73(_wrapreduction)\n",
      "        2    0.000    0.000    0.000    0.000 fromnumeric.py:74(<dictcomp>)\n",
      "    65536    0.357    0.000    0.357    0.000 tensor.py:25(wrapped)\n",
      "        1    0.000    0.000    0.000    0.000 tensor.py:443(__len__)\n",
      "        1    0.000    0.000    0.835    0.835 {built-in method builtins.exec}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.len}\n",
      "      4/2    0.000    0.000    0.000    0.000 {built-in method numpy.core._multiarray_umath.implement_array_function}\n",
      "    32768    0.004    0.000    0.004    0.000 {method 'add' of 'set' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'dim' of 'torch._C._TensorBase' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'reduce' of 'numpy.ufunc' objects}\n",
      "        4    0.000    0.000    0.000    0.000 {method 'reshape' of 'torch._C._TensorBase' objects}\n",
      "\n",
      "\n",
      "65536\n",
      "3.202491655945778\n",
      "         57187 function calls (57185 primitive calls) in 0.659 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        2    0.000    0.000    0.000    0.000 <__array_function__ internals>:2(prod)\n",
      "        2    0.000    0.000    0.000    0.000 <__array_function__ internals>:2(product)\n",
      "        1    0.000    0.000    0.659    0.659 <string>:1(<module>)\n",
      "        1    0.415    0.415    0.658    0.658 boxprop_optimized.py:53(relu)\n",
      "        4    0.000    0.000    0.000    0.000 fromnumeric.py:2838(_prod_dispatcher)\n",
      "        2    0.000    0.000    0.000    0.000 fromnumeric.py:2843(prod)\n",
      "        2    0.000    0.000    0.000    0.000 fromnumeric.py:3602(product)\n",
      "        2    0.000    0.000    0.000    0.000 fromnumeric.py:73(_wrapreduction)\n",
      "        2    0.000    0.000    0.000    0.000 fromnumeric.py:74(<dictcomp>)\n",
      "    44959    0.242    0.000    0.242    0.000 tensor.py:25(wrapped)\n",
      "        1    0.000    0.000    0.000    0.000 tensor.py:443(__len__)\n",
      "        1    0.000    0.000    0.659    0.659 {built-in method builtins.exec}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.len}\n",
      "      4/2    0.000    0.000    0.000    0.000 {built-in method numpy.core._multiarray_umath.implement_array_function}\n",
      "    12191    0.001    0.000    0.001    0.000 {method 'add' of 'set' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'dim' of 'torch._C._TensorBase' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'reduce' of 'numpy.ufunc' objects}\n",
      "        4    0.000    0.000    0.000    0.000 {method 'reshape' of 'torch._C._TensorBase' objects}\n",
      "\n",
      "\n",
      "1627\n",
      "2.5323768919333816\n"
     ]
    }
   ],
   "source": [
    "C = model_raw\n",
    "\n",
    "size=0.1\n",
    "upper_bound = center+size\n",
    "lower_bound = center-size\n",
    "tic = time.perf_counter()\n",
    "\n",
    "a_o = Box_o(upper_bound,lower_bound, False)\n",
    "\n",
    "a_o.convTranspose2d(weight=G.state_dict()['main.0.weight'], c_out=512, kernel_size=4, stride=1, padding=0, output_padding=0)\n",
    "a_o.batchNorm2d(mean=G.state_dict()['main.1.running_mean'], var=G.state_dict()['main.1.running_var'], eps=1e-05, weight=G.state_dict()['main.1.weight'], bias=G.state_dict()['main.1.bias'])\n",
    "a_o.relu()\n",
    "a_o.convTranspose2d(weight=G.state_dict()['main.3.weight'], c_out=256, kernel_size=4, stride=2, padding=1, output_padding=0)\n",
    "a_o.batchNorm2d(mean=G.state_dict()['main.4.running_mean'], var=G.state_dict()['main.4.running_var'], eps=1e-05, weight=G.state_dict()['main.4.weight'], bias=G.state_dict()['main.4.bias'])\n",
    "a_o.relu()\n",
    "a_o.convTranspose2d(weight=G.state_dict()['main.6.weight'], c_out=128, kernel_size=4, stride=2, padding=1, output_padding=0)\n",
    "a_o.batchNorm2d(mean=G.state_dict()['main.7.running_mean'], var=G.state_dict()['main.7.running_var'], eps=1e-05, weight=G.state_dict()['main.7.weight'], bias=G.state_dict()['main.7.bias'])\n",
    "cProfile.run('a_o.relu()')\n",
    "a_o.convTranspose2d(weight=G.state_dict()['main.9.weight'], c_out=64, kernel_size=4, stride=2, padding=1, output_padding=0)\n",
    "a_o.batchNorm2d(mean=G.state_dict()['main.10.running_mean'], var=G.state_dict()['main.10.running_var'], eps=1e-05, weight=G.state_dict()['main.10.weight'], bias=G.state_dict()['main.10.bias'])\n",
    "print(len(a_o.relu()))\n",
    "a_o.convTranspose2d(weight=G.state_dict()['main.12.weight'], c_out=1, kernel_size=1, stride=1, padding=2, output_padding=0)\n",
    "a_o.tanh()\n",
    "\n",
    "# b1 = Box_o(a_o.upper, a_o.lower, True)\n",
    "# b1.linear(C.state_dict()['model.fc1.weight'], C.state_dict()['model.fc1.bias'])\n",
    "# b1.relu()\n",
    "# b1.linear(C.state_dict()['model.fc2.weight'], C.state_dict()['model.fc2.bias'])\n",
    "# b1.relu()\n",
    "# b1.linear(C.state_dict()['model.out.weight'], C.state_dict()['model.out.bias'])\n",
    "\n",
    "print(time.perf_counter()-tic)\n",
    "\n",
    "\n",
    "\n",
    "size=0.00001\n",
    "upper_bound = center+size\n",
    "lower_bound = center-size\n",
    "\n",
    "tic = time.perf_counter()\n",
    "\n",
    "a_oo = Box_o(upper_bound,lower_bound, False)\n",
    "\n",
    "a_oo.convTranspose2d(weight=G.state_dict()['main.0.weight'], c_out=512, kernel_size=4, stride=1, padding=0, output_padding=0)\n",
    "a_oo.batchNorm2d(mean=G.state_dict()['main.1.running_mean'], var=G.state_dict()['main.1.running_var'], eps=1e-05, weight=G.state_dict()['main.1.weight'], bias=G.state_dict()['main.1.bias'])\n",
    "a_oo.relu()\n",
    "a_oo.convTranspose2d(weight=G.state_dict()['main.3.weight'], c_out=256, kernel_size=4, stride=2, padding=1, output_padding=0)\n",
    "a_oo.batchNorm2d(mean=G.state_dict()['main.4.running_mean'], var=G.state_dict()['main.4.running_var'], eps=1e-05, weight=G.state_dict()['main.4.weight'], bias=G.state_dict()['main.4.bias'])\n",
    "a_oo.relu()\n",
    "a_oo.convTranspose2d(weight=G.state_dict()['main.6.weight'], c_out=128, kernel_size=4, stride=2, padding=1, output_padding=0)\n",
    "a_oo.batchNorm2d(mean=G.state_dict()['main.7.running_mean'], var=G.state_dict()['main.7.running_var'], eps=1e-05, weight=G.state_dict()['main.7.weight'], bias=G.state_dict()['main.7.bias'])\n",
    "cProfile.run('a_oo.relu()')\n",
    "a_oo.convTranspose2d(weight=G.state_dict()['main.9.weight'], c_out=64, kernel_size=4, stride=2, padding=1, output_padding=0)\n",
    "a_oo.batchNorm2d(mean=G.state_dict()['main.10.running_mean'], var=G.state_dict()['main.10.running_var'], eps=1e-05, weight=G.state_dict()['main.10.weight'], bias=G.state_dict()['main.10.bias'])\n",
    "print(len(a_oo.relu()))\n",
    "a_oo.convTranspose2d(weight=G.state_dict()['main.12.weight'], c_out=1, kernel_size=1, stride=1, padding=2, output_padding=0)\n",
    "a_oo.tanh()\n",
    "\n",
    "# b2 = Box_o(a_oo.upper, a_oo.lower, True)\n",
    "# b2.linear(C.state_dict()['model.fc1.weight'], C.state_dict()['model.fc1.bias'])\n",
    "# b2.relu()\n",
    "# b2.linear(C.state_dict()['model.fc2.weight'], C.state_dict()['model.fc2.bias'])\n",
    "# b2.relu()\n",
    "# b2.linear(C.state_dict()['model.out.weight'], C.state_dict()['model.out.bias'])\n",
    "\n",
    "print(time.perf_counter()-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8192])\n",
      "torch.Size([16384])\n",
      "torch.Size([32768])\n",
      "         98376 function calls (98374 primitive calls) in 0.820 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        2    0.000    0.000    0.000    0.000 <__array_function__ internals>:2(prod)\n",
      "        2    0.000    0.000    0.000    0.000 <__array_function__ internals>:2(product)\n",
      "        1    0.000    0.000    0.820    0.820 <string>:1(<module>)\n",
      "        1    0.460    0.460    0.820    0.820 boxprop_optimized.py:53(relu)\n",
      "        4    0.000    0.000    0.000    0.000 fromnumeric.py:2838(_prod_dispatcher)\n",
      "        2    0.000    0.000    0.000    0.000 fromnumeric.py:2843(prod)\n",
      "        2    0.000    0.000    0.000    0.000 fromnumeric.py:3602(product)\n",
      "        2    0.000    0.000    0.000    0.000 fromnumeric.py:73(_wrapreduction)\n",
      "        2    0.000    0.000    0.000    0.000 fromnumeric.py:74(<dictcomp>)\n",
      "        3    0.000    0.000    0.000    0.000 iostream.py:197(schedule)\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:309(_is_master_process)\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:322(_schedule_flush)\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:384(write)\n",
      "        3    0.000    0.000    0.000    0.000 iostream.py:93(_event_pipe)\n",
      "        3    0.000    0.000    0.000    0.000 socket.py:342(send)\n",
      "    65536    0.355    0.000    0.355    0.000 tensor.py:25(wrapped)\n",
      "        1    0.000    0.000    0.000    0.000 tensor.py:443(__len__)\n",
      "        3    0.000    0.000    0.000    0.000 threading.py:1062(_wait_for_tstate_lock)\n",
      "        3    0.000    0.000    0.000    0.000 threading.py:1104(is_alive)\n",
      "        3    0.000    0.000    0.000    0.000 threading.py:506(is_set)\n",
      "        1    0.000    0.000    0.820    0.820 {built-in method builtins.exec}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.len}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.print}\n",
      "      4/2    0.000    0.000    0.000    0.000 {built-in method numpy.core._multiarray_umath.implement_array_function}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method posix.getpid}\n",
      "        3    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.lock' objects}\n",
      "    32768    0.005    0.000    0.005    0.000 {method 'add' of 'set' objects}\n",
      "        3    0.000    0.000    0.000    0.000 {method 'append' of 'collections.deque' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'dim' of 'torch._C._TensorBase' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'reduce' of 'numpy.ufunc' objects}\n",
      "        4    0.000    0.000    0.000    0.000 {method 'reshape' of 'torch._C._TensorBase' objects}\n",
      "\n",
      "\n",
      "torch.Size([65536])\n",
      "65536\n",
      "3.29635828291066\n",
      "torch.Size([8192])\n",
      "torch.Size([16384])\n",
      "torch.Size([32768])\n",
      "         67300 function calls (67298 primitive calls) in 0.724 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        2    0.000    0.000    0.000    0.000 <__array_function__ internals>:2(prod)\n",
      "        2    0.000    0.000    0.000    0.000 <__array_function__ internals>:2(product)\n",
      "        1    0.001    0.001    0.724    0.724 <string>:1(<module>)\n",
      "        1    0.443    0.443    0.723    0.723 boxprop_optimized.py:53(relu)\n",
      "        4    0.000    0.000    0.000    0.000 fromnumeric.py:2838(_prod_dispatcher)\n",
      "        2    0.000    0.000    0.000    0.000 fromnumeric.py:2843(prod)\n",
      "        2    0.000    0.000    0.000    0.000 fromnumeric.py:3602(product)\n",
      "        2    0.000    0.000    0.000    0.000 fromnumeric.py:73(_wrapreduction)\n",
      "        2    0.000    0.000    0.000    0.000 fromnumeric.py:74(<dictcomp>)\n",
      "        3    0.000    0.000    0.000    0.000 iostream.py:197(schedule)\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:309(_is_master_process)\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:322(_schedule_flush)\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:384(write)\n",
      "        3    0.000    0.000    0.000    0.000 iostream.py:93(_event_pipe)\n",
      "        3    0.000    0.000    0.000    0.000 socket.py:342(send)\n",
      "    49998    0.277    0.000    0.277    0.000 tensor.py:25(wrapped)\n",
      "        1    0.000    0.000    0.000    0.000 tensor.py:443(__len__)\n",
      "        3    0.000    0.000    0.000    0.000 threading.py:1062(_wait_for_tstate_lock)\n",
      "        3    0.000    0.000    0.000    0.000 threading.py:1104(is_alive)\n",
      "        3    0.000    0.000    0.000    0.000 threading.py:506(is_set)\n",
      "        1    0.000    0.000    0.724    0.724 {built-in method builtins.exec}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.len}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.print}\n",
      "      4/2    0.000    0.000    0.000    0.000 {built-in method numpy.core._multiarray_umath.implement_array_function}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method posix.getpid}\n",
      "        3    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.lock' objects}\n",
      "    17230    0.003    0.000    0.003    0.000 {method 'add' of 'set' objects}\n",
      "        3    0.000    0.000    0.000    0.000 {method 'append' of 'collections.deque' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'dim' of 'torch._C._TensorBase' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'reduce' of 'numpy.ufunc' objects}\n",
      "        4    0.000    0.000    0.000    0.000 {method 'reshape' of 'torch._C._TensorBase' objects}\n",
      "\n",
      "\n",
      "torch.Size([65536])\n",
      "61220\n",
      "2.9144538369728252\n"
     ]
    }
   ],
   "source": [
    "import time, cProfile\n",
    "torch.manual_seed(0)\n",
    "center = torch.randn(1,100,1,1)\n",
    "\n",
    "C = model_raw\n",
    "\n",
    "size=0.1\n",
    "upper_bound = center+size\n",
    "lower_bound = center-size\n",
    "tic = time.perf_counter()\n",
    "\n",
    "a_o = Box_o(upper_bound,lower_bound, False)\n",
    "\n",
    "a_o.convTranspose2d(weight=G.state_dict()['main.0.weight'], c_out=512, kernel_size=4, stride=1, padding=0, output_padding=0)\n",
    "a_o.batchNorm2d(mean=G.state_dict()['main.1.running_mean'], var=G.state_dict()['main.1.running_var'], eps=1e-05, weight=G.state_dict()['main.1.weight'], bias=G.state_dict()['main.1.bias'])\n",
    "a_o.relu()\n",
    "a_o.convTranspose2d(weight=G.state_dict()['main.3.weight'], c_out=256, kernel_size=4, stride=2, padding=1, output_padding=0)\n",
    "a_o.batchNorm2d(mean=G.state_dict()['main.4.running_mean'], var=G.state_dict()['main.4.running_var'], eps=1e-05, weight=G.state_dict()['main.4.weight'], bias=G.state_dict()['main.4.bias'])\n",
    "a_o.relu()\n",
    "a_o.convTranspose2d(weight=G.state_dict()['main.6.weight'], c_out=128, kernel_size=4, stride=2, padding=1, output_padding=0)\n",
    "a_o.batchNorm2d(mean=G.state_dict()['main.7.running_mean'], var=G.state_dict()['main.7.running_var'], eps=1e-05, weight=G.state_dict()['main.7.weight'], bias=G.state_dict()['main.7.bias'])\n",
    "cProfile.run('a_o.relu()')\n",
    "a_o.convTranspose2d(weight=G.state_dict()['main.9.weight'], c_out=64, kernel_size=4, stride=2, padding=1, output_padding=0)\n",
    "a_o.batchNorm2d(mean=G.state_dict()['main.10.running_mean'], var=G.state_dict()['main.10.running_var'], eps=1e-05, weight=G.state_dict()['main.10.weight'], bias=G.state_dict()['main.10.bias'])\n",
    "print(len(a_o.relu()))\n",
    "a_o.convTranspose2d(weight=G.state_dict()['main.12.weight'], c_out=1, kernel_size=1, stride=1, padding=2, output_padding=0)\n",
    "a_o.tanh()\n",
    "\n",
    "# b1 = Box_o(a_o.upper, a_o.lower, True)\n",
    "# b1.linear(C.state_dict()['model.fc1.weight'], C.state_dict()['model.fc1.bias'])\n",
    "# b1.relu()\n",
    "# b1.linear(C.state_dict()['model.fc2.weight'], C.state_dict()['model.fc2.bias'])\n",
    "# b1.relu()\n",
    "# b1.linear(C.state_dict()['model.out.weight'], C.state_dict()['model.out.bias'])\n",
    "\n",
    "print(time.perf_counter()-tic)\n",
    "\n",
    "\n",
    "\n",
    "size=0.001\n",
    "upper_bound = center+size\n",
    "lower_bound = center-size\n",
    "\n",
    "tic = time.perf_counter()\n",
    "\n",
    "a_oo = Box_o(upper_bound,lower_bound, False)\n",
    "\n",
    "a_oo.convTranspose2d(weight=G.state_dict()['main.0.weight'], c_out=512, kernel_size=4, stride=1, padding=0, output_padding=0)\n",
    "a_oo.batchNorm2d(mean=G.state_dict()['main.1.running_mean'], var=G.state_dict()['main.1.running_var'], eps=1e-05, weight=G.state_dict()['main.1.weight'], bias=G.state_dict()['main.1.bias'])\n",
    "a_oo.relu()\n",
    "a_oo.convTranspose2d(weight=G.state_dict()['main.3.weight'], c_out=256, kernel_size=4, stride=2, padding=1, output_padding=0)\n",
    "a_oo.batchNorm2d(mean=G.state_dict()['main.4.running_mean'], var=G.state_dict()['main.4.running_var'], eps=1e-05, weight=G.state_dict()['main.4.weight'], bias=G.state_dict()['main.4.bias'])\n",
    "a_oo.relu()\n",
    "a_oo.convTranspose2d(weight=G.state_dict()['main.6.weight'], c_out=128, kernel_size=4, stride=2, padding=1, output_padding=0)\n",
    "a_oo.batchNorm2d(mean=G.state_dict()['main.7.running_mean'], var=G.state_dict()['main.7.running_var'], eps=1e-05, weight=G.state_dict()['main.7.weight'], bias=G.state_dict()['main.7.bias'])\n",
    "cProfile.run('a_oo.relu()')\n",
    "a_oo.convTranspose2d(weight=G.state_dict()['main.9.weight'], c_out=64, kernel_size=4, stride=2, padding=1, output_padding=0)\n",
    "a_oo.batchNorm2d(mean=G.state_dict()['main.10.running_mean'], var=G.state_dict()['main.10.running_var'], eps=1e-05, weight=G.state_dict()['main.10.weight'], bias=G.state_dict()['main.10.bias'])\n",
    "print(len(a_oo.relu()))\n",
    "a_oo.convTranspose2d(weight=G.state_dict()['main.12.weight'], c_out=1, kernel_size=1, stride=1, padding=2, output_padding=0)\n",
    "a_oo.tanh()\n",
    "\n",
    "# b2 = Box_o(a_oo.upper, a_oo.lower, True)\n",
    "# b2.linear(C.state_dict()['model.fc1.weight'], C.state_dict()['model.fc1.bias'])\n",
    "# b2.relu()\n",
    "# b2.linear(C.state_dict()['model.fc2.weight'], C.state_dict()['model.fc2.bias'])\n",
    "# b2.relu()\n",
    "# b2.linear(C.state_dict()['model.out.weight'], C.state_dict()['model.out.bias'])\n",
    "\n",
    "print(time.perf_counter()-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
