{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../pretrained_classifiers\")\n",
    "sys.path.insert(0, \"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "import numpy as np\n",
    "import io\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "import torch.onnx\n",
    "from multiprocessing import Pool\n",
    "from joblib import Parallel, delayed\n",
    "import _thread as thread\n",
    "from numba import njit, prange\n",
    "import time\n",
    "import itertools\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from utee import selector\n",
    "from boxprop import *\n",
    "from boxprop_optimized import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_gpu = 1 if torch.cuda.is_available() else 0\n",
    "\n",
    "# load the models\n",
    "from dcgan import Discriminator, Generator\n",
    "\n",
    "D = Discriminator(ngpu=1).eval()\n",
    "G = Generator(ngpu=1).eval()\n",
    "\n",
    "# load weights\n",
    "D.load_state_dict(torch.load('weights/netD_epoch_199.pth',map_location=torch.device('cpu')))\n",
    "G.load_state_dict(torch.load('weights/netG_epoch_199.pth',map_location=torch.device('cpu')))\n",
    "if torch.cuda.is_available():\n",
    "    D = D.cuda()\n",
    "    G = G.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generate some images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 1\n",
    "latent_size = 100\n",
    "\n",
    "fixed_noise = torch.randn(batch_size, latent_size, 1, 1)\n",
    "if torch.cuda.is_available():\n",
    "    fixed_noise = fixed_noise.cuda()\n",
    "fake_images = G(fixed_noise)\n",
    "\n",
    "\n",
    "# z = torch.randn(batch_size, latent_size).cuda()\n",
    "# z = Variable(z)\n",
    "# fake_images = G(z)\n",
    "\n",
    "fake_images_np = fake_images.cpu().detach().numpy()\n",
    "fake_images_np = fake_images_np.reshape(fake_images_np.shape[0], 3, 32, 32)\n",
    "fake_images_np = fake_images_np.transpose((0, 2, 3, 1))\n",
    "R, C = 5, 5\n",
    "for i in range(batch_size):\n",
    "    plt.subplot(R, C, i + 1)\n",
    "    plt.imshow(fake_images_np[i], interpolation='bilinear')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1157], grad_fn=<SqueezeBackward1>)\n"
     ]
    }
   ],
   "source": [
    "outputs = D(fake_images)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.18346167192794383\n",
      "1\n",
      "0.38017848797608167\n",
      "2\n",
      "0.6719304139260203\n",
      "3\n",
      "1.2979839300969616\n",
      "3\n",
      "0.0011765899835154414\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "print(0)\n",
    "tic = time.perf_counter()\n",
    "a_o = Box_o(fixed_noise,fixed_noise,False)\n",
    "a_o.convTranspose2d(weight=G.state_dict()['main.0.weight'], c_out=512, kernel_size=4, stride=1, padding=0, output_padding=0)\n",
    "a_o.batchNorm2d(mean=G.state_dict()['main.1.running_mean'], var=G.state_dict()['main.1.running_var'], eps=1e-05, weight=G.state_dict()['main.1.weight'], bias=G.state_dict()['main.1.bias'])\n",
    "a_o.relu()\n",
    "print(time.perf_counter()-tic)\n",
    "print(1)\n",
    "tic = time.perf_counter()\n",
    "a_o.convTranspose2d(weight=G.state_dict()['main.3.weight'], c_out=256, kernel_size=4, stride=2, padding=1, output_padding=0)\n",
    "a_o.batchNorm2d(mean=G.state_dict()['main.4.running_mean'], var=G.state_dict()['main.4.running_var'], eps=1e-05, weight=G.state_dict()['main.4.weight'], bias=G.state_dict()['main.4.bias'])\n",
    "a_o.relu()\n",
    "print(time.perf_counter()-tic)\n",
    "print(2)\n",
    "tic = time.perf_counter()\n",
    "a_o.convTranspose2d(weight=G.state_dict()['main.6.weight'], c_out=128, kernel_size=4, stride=2, padding=1, output_padding=0)\n",
    "a_o.batchNorm2d(mean=G.state_dict()['main.7.running_mean'], var=G.state_dict()['main.7.running_var'], eps=1e-05, weight=G.state_dict()['main.7.weight'], bias=G.state_dict()['main.7.bias'])\n",
    "a_o.relu()\n",
    "print(time.perf_counter()-tic)\n",
    "print(3)\n",
    "tic = time.perf_counter()\n",
    "a_o.convTranspose2d(weight=G.state_dict()['main.9.weight'], c_out=64, kernel_size=4, stride=2, padding=1, output_padding=0)\n",
    "a_o.batchNorm2d(mean=G.state_dict()['main.10.running_mean'], var=G.state_dict()['main.10.running_var'], eps=1e-05, weight=G.state_dict()['main.10.weight'], bias=G.state_dict()['main.10.bias'])\n",
    "a_o.relu()\n",
    "print(time.perf_counter()-tic)\n",
    "print(3)\n",
    "tic = time.perf_counter()\n",
    "a_o.convTranspose2d(weight=G.state_dict()['main.12.weight'], c_out=3, kernel_size=1, stride=1, padding=0, output_padding=0)\n",
    "a_o.tanh()\n",
    "print(time.perf_counter()-tic)\n",
    "print(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEcAAABICAYAAACk5ujKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAGf0lEQVR4nO2bzW9cVxmHn9+5H/Mdx7HjNEpamiI2pQuoKljAggVIiA1iRxZsw6YSSHSBuuofAGWJVER3SGzKAlWVKhYsWKGGqlBKCIoDqp2YhMSux56xZ+7Hy2ImzTide+2ZuZ54onmkK13fue857/35nPec8957ZGbMGY573A6cZObi5DAXJ4e5ODnMxclhLk4OE4kj6duSrku6IemnRTl1UtC48xxJHvAv4FvAOvAecNnM/lGce4+XSVrOV4AbZnbTzLrAb4HvFuPWycCfwPYCsDbw9zrw1TwDSSdyOm5mGnZ9EnGGFfiZh5d0BbgyQT3FIYZ4mM0k3WodeHrg74vA7UdvMrM3zOwlM3tpgrqKQQEjPbKZjXXQa3U3gUtACPwV+OIhNvZYDoep5plfqZpKvqmEBVXPTi2esiAILMvfsbuVmcWSXgbeBTzgTTP7aNzyjhPnOarLFYIoJDEP51JqlSrLp1e4ef3jTLtJYg5m9g7wziRlHDcSlEOPc40anlch9AOCwONUo87ZxXOsrW5k2k4kzixQKQU8tVCntl+mdjbADyq4SkC1HuAHLaQo0/aJF0dpiosTyrUyJS9EzuGlDhdBK92lE3UybZ94cZI0oZtGhHXDohjSlDQUURIRb28TR09oyymHHnGSEifZk5cogZ39iOZ2Ey8RhB6efCyNaG1uk0TZtmOvrcah6BnyqWpAJ0roRGnufb4nFhohvg9UPTznSKKIdqtD6xNIMmbIMynOg4lu2Yc47R1HpgLEQPSwnKzlw8yJ4+hNqrIjxehkiTNzya6Ug8KUKmXCculY6po5cQa58Mx5Fs7UkBveIEt4VCYYc2ZDHKfeVPcRVs6tUApKxFE81KyK0WCUgHSQGRjKK3h+HbM2adQ68Eu8F9NtRyQZo1V8iDChB2lOFJwBcap4boHEUlAbBgaQ2x/fYq+zn2m5k1OqgKoP3Rz9Tvho5eg9RkpvjBIHwrF0QKxR8IBaAPsGnWjmRqsQWO6fG59OTh4Q+ITLZ/Eq1bFKT4BOApZk33OCu1UEbNF7jAEk/EqVF7/5DcyPad7Z4u7qGlv/zU49ZJGm+VnTE9ZyAh7+v4zhUz3D+cbS4hJ7WzHtrRZOXcpjNKCYz0h/gBPYcg6JIQ6cH9PcvsWd1X+zs3mfMGhTKsF+u9CaTpo4CciBPLAUwgA6EYOPIcDSmLWb12jev0en1cXKEATFe3PCRqsS+CG4BNIOOrOItnZIU+sHiISR3q0ckdlceEosLS2wE67QbXZg9x7QOtRsVMZeeEp6WtIfJV2T9JGkH/WvvybplqQP+sd3inYaMxzGmaBLtdqF0pDwORjDC+YoxcbAT8zsfUkN4C+S/tD/7Rdm9rPjcEyCctmnfKaOQuGCDkQxDKR8Fy+GnF5o0NqKuHu7WbgPh4pjZhvARv98R9I1eu/JjxcHac1IEV1fqN4g6EK004Q4BhwXnrqAF8bsNjePy4WjI+lZ4MvAn/uXXpb0N0lvSlos0jETdPyUTuxIVUHBaVypAWWHK4FfrZC2Q+7fabH9SfFxCEYQR1IdeAv4sZk1gV8Cnwe+RK9l/TzD7oqkq5KujuRZCrQdVl6kXl3BdzViObyGw1/yKZ0u888bq6yvbtLNW2FOwJFGK0kB8Dbwrpm9PuT3Z4G3zeyFQ8oZ7RsHValdeoHFZy6C89lrbbIXrdNO1uD6LnSskJF97E9QJAn4NXBtUBhJ5/vxCOB7wN8nd3OQFKxD+1YHZxtUGlXivV327m7C3i5ExQiTx6EtR9LXgT8BH/Y8BuBV4DK9LmXAf4AfDoiVVdaIjyNQHa9UoVSukaZd9nf/B2l3tGIOYTYngZ/i41wApKRp9uvbcZlxcY6XJ+bVzDSZi5PDtFMWD1aO96Zc73JOnZ/LMppqzAGQdHXaH0+OW+e8W+UwFyeHxyHOG7NS59Rjziwx71Y5TE2caezNKjylO+7n/SNuBfCAVeA5Hm4FeP4Y6jkPvNg/b9DbD/Y88BrwyqjlTavlTGVvlpltmNn7/fMdYKKU7rTEGbY361jz0EWkdKclzpH2ZhVW2Zgp3UeZljhH2ptVBP2U7lvAb8zsdwBmdsfMEjNLgV/R6+aHMi1x3gO+IOmSpBD4PvD7oivJS+kO3HbklO5UVuVT3Jv1NeAHwIeSPuhfexW4LOlASvcohc1nyDnMZ8g5zMXJYS5ODnNxcpiLk8NcnBzm4uQwFyeH/wMDRK8DMzCH0wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fake_images_np = a_o.upper.numpy()\n",
    "fake_images_np = fake_images_np.reshape(fake_images_np.shape[0], 3, 32, 32)\n",
    "fake_images_np = fake_images_np.transpose((0, 2, 3, 1))\n",
    "R, C = 5, 5\n",
    "for i in range(batch_size):\n",
    "    plt.subplot(R, C, i + 1)\n",
    "    plt.imshow(fake_images_np[i], interpolation='bilinear')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building and initializing cifar10 parameters\n",
      "Sequential(\n",
      "  (0): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "  (2): ReLU()\n",
      "  (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "  (5): ReLU()\n",
      "  (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (8): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "  (9): ReLU()\n",
      "  (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (11): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "  (12): ReLU()\n",
      "  (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (14): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (15): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "  (16): ReLU()\n",
      "  (17): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (18): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "  (19): ReLU()\n",
      "  (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (21): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (22): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "  (23): ReLU()\n",
      "  (24): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "Sequential(\n",
      "  (0): Linear(in_features=1024, out_features=10, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CIFAR(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "    (5): ReLU()\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "    (9): ReLU()\n",
      "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "    (12): ReLU()\n",
      "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (14): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "    (16): ReLU()\n",
      "    (17): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "    (19): ReLU()\n",
      "    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (21): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (22): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "    (23): ReLU()\n",
      "    (24): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=10, bias=True)\n",
      "  )\n",
      "), Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), ReLU(), Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), ReLU(), MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False), Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), ReLU(), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), ReLU(), MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False), Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), ReLU(), Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), ReLU(), MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False), Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1)), BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True), ReLU(), MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False), Linear(in_features=1024, out_features=10, bias=True)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_raw, ds_fetcher, is_imagenet = selector.select('cifar10')\n",
    "# ds_val = ds_fetcher(batch_size=10, train=False, val=True)\n",
    "# for idx, (data, target) in enumerate(ds_val):\n",
    "#     data =  Variable(torch.FloatTensor(data))\n",
    "#     output = model_raw(data)\n",
    "#     print(D(data))\n",
    "l = [module for module in model_raw.modules() if type(module) != nn.Sequential]\n",
    "print(l)\n",
    "model_raw.eval()\n",
    "data = a_o.upper\n",
    "output = model_raw(data)\n",
    "list(output[0].cpu().detach().numpy()).index(max(output[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of lipprop_optimized failed: Traceback (most recent call last):\n",
      "  File \"/Users/ksarangmath/anaconda3/envs/eran/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/Users/ksarangmath/anaconda3/envs/eran/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 394, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/Users/ksarangmath/anaconda3/envs/eran/lib/python3.6/imp.py\", line 315, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/Users/ksarangmath/anaconda3/envs/eran/lib/python3.6/importlib/__init__.py\", line 166, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 618, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 674, in exec_module\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 781, in get_code\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 741, in source_to_code\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"../lipprop_optimized.py\", line 58\n",
      "    for i in prange(w0)ž\n",
      "                       ^\n",
      "SyntaxError: invalid syntax\n",
      "]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.1\n",
      "0.2\n",
      "12.44116138597019\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "C = model_raw\n",
    "print(0)\n",
    "tic = time.perf_counter()\n",
    "b = Box_o(a_o.upper, a_o.lower, True)\n",
    "b.conv2d(weight=C.state_dict()['features.0.weight'], c_out=128, kernel_size=3, stride=1, padding=1, bias=C.state_dict()['features.0.bias'])\n",
    "print(0.1)\n",
    "b.batchNorm2d(mean=C.state_dict()['features.1.running_mean'], var=C.state_dict()['features.1.running_var'], eps=1e-05, weight=None, bias=None)\n",
    "print(0.2)\n",
    "b.relu()\n",
    "\n",
    "print(time.perf_counter()-tic)\n",
    "print(1)\n",
    "tic = time.perf_counter()\n",
    "\n",
    "b.conv2d(weight=C.state_dict()['features.3.weight'], c_out=128, kernel_size=3, stride=1, padding=1, bias=C.state_dict()['features.3.bias'])\n",
    "b.batchNorm2d(mean=C.state_dict()['features.4.running_mean'], var=C.state_dict()['features.4.running_var'], eps=1e-05, weight=None, bias=None)\n",
    "b.relu()\n",
    "\n",
    "print(time.perf_counter()-tic)\n",
    "print(2)\n",
    "tic = time.perf_counter()\n",
    "\n",
    "b.maxpool2d(2)\n",
    "b.conv2d(weight=C.state_dict()['features.7.weight'], c_out=256, kernel_size=3, stride=1, padding=1, bias=C.state_dict()['features.7.bias'])\n",
    "b.batchNorm2d(mean=C.state_dict()['features.8.running_mean'], var=C.state_dict()['features.8.running_var'], eps=1e-05, weight=None, bias=None)\n",
    "b.relu()\n",
    "\n",
    "print(time.perf_counter()-tic)\n",
    "print(3)\n",
    "tic = time.perf_counter()\n",
    "\n",
    "b.conv2d(weight=C.state_dict()['features.10.weight'], c_out=256, kernel_size=3, stride=1, padding=1, bias=C.state_dict()['features.10.bias'])\n",
    "b.batchNorm2d(mean=C.state_dict()['features.11.running_mean'], var=C.state_dict()['features.11.running_var'], eps=1e-05, weight=None, bias=None)\n",
    "b.relu()\n",
    "\n",
    "print(time.perf_counter()-tic)\n",
    "print(4)\n",
    "tic = time.perf_counter()\n",
    "\n",
    "b.maxpool2d(2)\n",
    "b.conv2d(weight=C.state_dict()['features.14.weight'], c_out=512, kernel_size=3, stride=1, padding=1, bias=C.state_dict()['features.14.bias'])\n",
    "b.batchNorm2d(mean=C.state_dict()['features.15.running_mean'], var=C.state_dict()['features.15.running_var'], eps=1e-05, weight=None, bias=None)\n",
    "b.relu()\n",
    "\n",
    "print(time.perf_counter()-tic)\n",
    "print(5)\n",
    "tic = time.perf_counter()\n",
    "\n",
    "b.conv2d(weight=C.state_dict()['features.17.weight'], c_out=512, kernel_size=3, stride=1, padding=1, bias=C.state_dict()['features.17.bias'])\n",
    "b.batchNorm2d(mean=C.state_dict()['features.18.running_mean'], var=C.state_dict()['features.18.running_var'], eps=1e-05, weight=None, bias=None)\n",
    "b.relu()\n",
    "\n",
    "print(time.perf_counter()-tic)\n",
    "print(6)\n",
    "tic = time.perf_counter()\n",
    "\n",
    "b.maxpool2d(2)\n",
    "b.conv2d(weight=C.state_dict()['features.21.weight'], c_out=1024, kernel_size=3, stride=1, padding=0, bias=C.state_dict()['features.21.bias'])\n",
    "b.batchNorm2d(mean=C.state_dict()['features.22.running_mean'], var=C.state_dict()['features.22.running_var'], eps=1e-05, weight=None, bias=None)\n",
    "b.relu()\n",
    "\n",
    "print(time.perf_counter()-tic)\n",
    "print(7)\n",
    "tic = time.perf_counter()\n",
    "\n",
    "b.maxpool2d(2)\n",
    "b.linear(weight=C.state_dict()['classifier.0.weight'], bias=C.state_dict()['classifier.0.bias'])\n",
    "\n",
    "print(time.perf_counter()-tic)\n",
    "print(8)\n",
    "\n",
    "print(list(b.upper).index(max(b.upper)), 'mine')\n",
    "print(list(output[0]).index(max(output[0])), 'real')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i=18\n",
    "# j=30\n",
    "# print(convW2[4*j:4*j+4,16*i:16+16*i])\n",
    "# print(C.state_dict()['features.21.weight'][j][i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "iii = torch.randn(1,512,4,4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.93738559493795\n",
      "7\n",
      "0.18203699099831283\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "C = model_raw\n",
    "tic = time.perf_counter()\n",
    "\n",
    "b = Box_o(iii, iii, True)\n",
    "\n",
    "convW2 = b.conv2d(weight=C.state_dict()['features.21.weight'], c_out=1024, kernel_size=3, stride=1, padding=0, bias=C.state_dict()['features.21.bias'])\n",
    "b.batchNorm2d(mean=C.state_dict()['features.22.running_mean'], var=C.state_dict()['features.22.running_var'], eps=1e-05, weight=None, bias=None)\n",
    "b.relu()\n",
    "\n",
    "print(time.perf_counter()-tic)\n",
    "print(7)\n",
    "tic = time.perf_counter()\n",
    "\n",
    "b.maxpool2d(2)\n",
    "b.linear(weight=C.state_dict()['classifier.0.weight'], bias=C.state_dict()['classifier.0.bias'])\n",
    "\n",
    "\n",
    "lip = b.getLip()\n",
    "\n",
    "print(time.perf_counter()-tic)\n",
    "print(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "437.4947"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id = np.identity(100)*30\n",
    "id[3,3]=50\n",
    "\n",
    "print(np.linalg.norm(id,ord=2))\n",
    "np.count_nonzero(lip[1])\n",
    "np.product(lip[1].shape)\n",
    "# print(np.sum(lip[1]-lip[2]))\n",
    "lip[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.4169, -0.6115, -0.0629,  0.4360, -0.1867],\n",
       "          [ 0.1699,  0.0829, -0.4691,  0.0837,  0.3754],\n",
       "          [-0.5965,  0.7514,  0.0433, -1.1748, -0.0266],\n",
       "          [-0.3236,  0.3251,  0.7135,  0.0629, -0.3227],\n",
       "          [-0.0399, -0.0022,  0.2679,  0.4698,  0.1570]]]],\n",
       "       grad_fn=<SlowConvTranspose2DBackward>)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> m = nn.ConvTranspose2d(1, 1, 3, stride=1, bias=False)\n",
    ">>> # non-square kernels and unequal stride and with padding\n",
    ">>> input = torch.randn(1, 1, 3, 3)\n",
    ">>> output = m(input)\n",
    "input=input.numpy()\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "for i in range(5):\n",
    "    torch.randn(1,100,1,1)+0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=torch.randn(1,100,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(4096,8192)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "upper = np.ones((4096,4096))\n",
    "print(upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = C.state_dict()['features.22.running_var'].numpy()\n",
    "step = upper.shape[0]//len(var)\n",
    "eps=1e-5\n",
    "for i in range(len(var)):\n",
    "    upper[i*step:i*step+step] *= 1/math.sqrt(var[i]+eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.0299, -0.1573, -0.0599,  0.    , -0.0523,  0.0366, -0.0046,\n",
       "         0.    ,  0.0858, -0.0138,  0.0403,  0.    ,  0.    ,  0.    ,\n",
       "         0.    ,  0.    ],\n",
       "       [ 0.    , -0.0299, -0.1573, -0.0599,  0.    , -0.0523,  0.0366,\n",
       "        -0.0046,  0.    ,  0.0858, -0.0138,  0.0403,  0.    ,  0.    ,\n",
       "         0.    ,  0.    ],\n",
       "       [ 0.    ,  0.    ,  0.    ,  0.    , -0.0299, -0.1573, -0.0599,\n",
       "         0.    , -0.0523,  0.0366, -0.0046,  0.    ,  0.0858, -0.0138,\n",
       "         0.0403,  0.    ],\n",
       "       [ 0.    ,  0.    ,  0.    ,  0.    ,  0.    , -0.0299, -0.1573,\n",
       "        -0.0599,  0.    , -0.0523,  0.0366, -0.0046,  0.    ,  0.0858,\n",
       "        -0.0138,  0.0403],\n",
       "       [-0.0569,  0.0309, -0.0848,  0.    ,  0.1172,  0.0266, -0.1015,\n",
       "         0.    ,  0.035 , -0.1561, -0.0932,  0.    ,  0.    ,  0.    ,\n",
       "         0.    ,  0.    ]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convW2[0:5,0:16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = sparse.csr_matrix(sparse.eye(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.0299 -0.1573 -0.0599 ...  0.      0.      0.    ]\n",
      " [ 0.     -0.0299 -0.1573 ...  0.      0.      0.    ]\n",
      " [ 0.      0.      0.     ... -0.0776 -0.0888  0.    ]\n",
      " ...\n",
      " [ 0.     -0.0474  0.0154 ...  0.      0.      0.    ]\n",
      " [ 0.      0.      0.     ...  0.1143  0.0379  0.    ]\n",
      " [ 0.      0.      0.     ...  0.13    0.1143  0.0379]]\n",
      "18874368\n"
     ]
    }
   ],
   "source": [
    "print(convW2.toarray())\n",
    "print(convW2.count_nonzero())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   3,    3,    7],\n",
       "       [   4,    4,    7],\n",
       "       [   5,    5,    7],\n",
       "       [  54,   54,    7],\n",
       "       [ 342,  342,    7],\n",
       "       [ 534,  534,    7],\n",
       "       [ 645,  645,    7],\n",
       "       [ 875,  875,    7],\n",
       "       [3234, 3234,    7],\n",
       "       [3545, 3545,    7]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tem = np.zeros(10000,dtype=np.int32)\n",
    "tem[[4,5,3,54,342,645,3234,534,3545,875]]=7\n",
    "dat = np.vstack((np.nonzero(tem),np.nonzero(tem),tem[np.nonzero(tem)])).T\n",
    "datt = np.vstack([dat,dat])\n",
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = sparse.coo_matrix((dat[2],(dat[0],dat[1])),dtype=np.float32,shape=(10000,10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.toarray()[4][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar = [[np.array([1,2])],[np.array([3,4]),np.array([3,4])]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'T'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-a252d5acf600>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'T'"
     ]
    }
   ],
   "source": [
    "ar.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [3,4,5]\n",
    "b = [5,6,6]\n",
    "a.extend(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nonzero(tem)[0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.14842448 -0.6944333 ]\n",
      " [-0.57033579 -0.05205047]] [[0.10357181 0.00570077]\n",
      " [0.55918761 0.93485761]]\n"
     ]
    }
   ],
   "source": [
    "amin = np.random.rand(2,2)*-1\n",
    "amax = np.random.rand(2,2)\n",
    "print(amin,amax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.14842448, -0.6944333 ],\n",
       "       [-0.57033579,  0.93485761]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "np.where(-amin > amax, amin, amax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 3.5228,  1.9876,  1.6766,  4.1924],\n",
       "          [ 2.5091,  1.9218,  2.7797,  2.0597],\n",
       "          [ 1.4829, -0.3418,  0.8780,  1.8466],\n",
       "          [ 2.2855, -0.3121,  1.9576,  2.8220]],\n",
       "\n",
       "         [[ 0.7745,  1.3710,  1.8567,  2.3286],\n",
       "          [ 1.8731,  1.3542,  0.5543,  2.5945],\n",
       "          [ 2.5615,  1.8877,  1.3519,  1.4698],\n",
       "          [ 1.6809, -0.2187,  2.3071,  2.8216]],\n",
       "\n",
       "         [[ 1.5622,  2.3852,  3.1799,  2.3485],\n",
       "          [ 1.0983,  2.9149,  2.4529,  1.6607],\n",
       "          [ 2.1374,  1.1696,  3.5923,  1.8019],\n",
       "          [ 2.0163,  1.3038,  1.8148, -0.6180]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 2.8361,  2.3777,  1.9634,  0.7622],\n",
       "          [ 1.4321,  3.0271,  1.3039,  1.8503],\n",
       "          [ 0.9815,  4.4549,  1.3696,  1.4349],\n",
       "          [ 1.3524,  2.2074,  0.1652,  2.9107]],\n",
       "\n",
       "         [[ 2.1471,  2.2217, -0.0359,  1.9756],\n",
       "          [ 1.5435,  2.1295,  0.4581,  1.9453],\n",
       "          [ 2.9850,  2.1370,  2.0553,  3.1757],\n",
       "          [ 1.1225,  1.9675,  2.0867,  2.2552]],\n",
       "\n",
       "         [[ 1.9635,  2.6698,  3.9106,  3.2776],\n",
       "          [ 2.0973,  1.9437,  3.1124,  2.2165],\n",
       "          [ 0.9714,  0.5576,  0.8928,  1.3215],\n",
       "          [ 3.0066,  2.2600,  2.2136,  1.8920]]]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000000000"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dum = np.array([-1,1,2,-3])\n",
    "dum*(dum>0)\n",
    "10**10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8924132661.33773"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(np.random.rand(10,3084)*100000000,ord=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv\n",
      "7.6857533\n",
      "bn\n",
      "60.97663\n",
      "relu\n",
      "51.37341\n"
     ]
    }
   ],
   "source": [
    "iii=torch.randn(1,3,32,32)\n",
    "C = model_raw\n",
    "\n",
    "b = Box_o(iii+0.1, iii-0.1, True)\n",
    "cl = np.copy(b.conv2d(weight=C.state_dict()['features.0.weight'], c_out=128, kernel_size=3, stride=1, padding=1, bias=C.state_dict()['features.0.bias']))\n",
    "\n",
    "bl = np.copy(b.batchNorm2d(mean=C.state_dict()['features.1.running_mean'], var=C.state_dict()['features.1.running_var'], eps=1e-05, weight=None, bias=None))\n",
    "\n",
    "b.relu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.24944614 -0.22445156  0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [-0.25780773 -0.24944614 -0.22445156 ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.         -0.25780773 -0.24944614 ...  0.          0.\n",
      "   0.        ]\n",
      " ...\n",
      " [ 0.          0.          0.         ...  0.07296999  0.27267373\n",
      "   0.        ]\n",
      " [ 0.          0.          0.         ...  0.08814757  0.07296999\n",
      "   0.27267373]\n",
      " [ 0.          0.          0.         ...  0.          0.08814757\n",
      "   0.07296999]]\n",
      "[[-0.63650775 -0.57272947  0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [-0.6578439  -0.63650775 -0.57272947 ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.         -0.6578439  -0.63650775 ...  0.          0.\n",
      "   0.        ]\n",
      " ...\n",
      " [ 0.          0.          0.         ...  0.2762808   1.0324041\n",
      "   0.        ]\n",
      " [ 0.          0.          0.         ...  0.33374655  0.2762808\n",
      "   1.0324041 ]\n",
      " [ 0.          0.          0.         ...  0.          0.33374655\n",
      "   0.2762808 ]]\n"
     ]
    }
   ],
   "source": [
    "bl[0][0]\n",
    "print(cl)\n",
    "print(bl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.5518)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/np.sqrt(C.state_dict()['features.1.running_var'][0]+.1e-05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.636536660052"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2.5518*-0.24944614"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0000002"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = torch.randn(100)\n",
    "np.linalg.norm((vec+0.1)-(vec-0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
